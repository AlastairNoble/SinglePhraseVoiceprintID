{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = os.listdir('alexa/')\n",
    "speakers = speakers[:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alexa/anfcucvo/1.wav</td>\n",
       "      <td>anfcucvo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alexa/anfcucvo/2.wav</td>\n",
       "      <td>anfcucvo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alexa/anfcucvo/3.wav</td>\n",
       "      <td>anfcucvo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alexa/anfcucvo/4.wav</td>\n",
       "      <td>anfcucvo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alexa/anfcucvo/5.wav</td>\n",
       "      <td>anfcucvo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               filepath   speaker\n",
       "0  alexa/anfcucvo/1.wav  anfcucvo\n",
       "1  alexa/anfcucvo/2.wav  anfcucvo\n",
       "2  alexa/anfcucvo/3.wav  anfcucvo\n",
       "3  alexa/anfcucvo/4.wav  anfcucvo\n",
       "4  alexa/anfcucvo/5.wav  anfcucvo"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['filepath', 'speaker'])\n",
    "for speaker in speakers:\n",
    "    files = os.listdir('alexa/{}/'.format(speaker))\n",
    "    for file in files:\n",
    "        filepath = 'alexa/{}/{}'.format(speaker, file)\n",
    "        df = df.append({'filepath':filepath, 'speaker':speaker}, ignore_index=True)\n",
    "print(len(speakers))\n",
    "df.head() # this is just a print statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>alexa/bfeciyuh/3.wav</td>\n",
       "      <td>bfeciyuh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>alexa/dsvhdyry/3.wav</td>\n",
       "      <td>dsvhdyry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>alexa/lbapynyb/3.wav</td>\n",
       "      <td>lbapynyb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>alexa/wnzlydvj/3.wav</td>\n",
       "      <td>wnzlydvj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>alexa/kpkwyaut/4.wav</td>\n",
       "      <td>kpkwyaut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 filepath   speaker\n",
       "11   alexa/bfeciyuh/3.wav  bfeciyuh\n",
       "47   alexa/dsvhdyry/3.wav  dsvhdyry\n",
       "187  alexa/lbapynyb/3.wav  lbapynyb\n",
       "317  alexa/wnzlydvj/3.wav  wnzlydvj\n",
       "158  alexa/kpkwyaut/4.wav  kpkwyaut"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size = 0.25, stratify = df['speaker'])\n",
    "# the stratify parameter makes the function split data evenly over the speakers column\n",
    "# this is so we dont get all files of the same speaker in the test set and not the training set\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(filename):\n",
    "    \n",
    "    X, sample_rate = librosa.load(filename, res_type='kaiser_fast')\n",
    "    \n",
    "    # librosa returns an array of 40 arrays, one for each mfcc\n",
    "    # np.mean takes the mean of each array, so we will be left with an array of size 40\n",
    "    # the n_mfcc=40 parameter means return 40 mfccs\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "      \n",
    "    return mfccs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out the function on one of the files\n",
    "# print(extract_features(train['filepath'][11]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the extract features to every element in train and test\n",
    "train_features = train['filepath'].apply(extract_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11     [-597.6613159179688, 75.76461029052734, -2.416...\n",
       "47     [-453.39544677734375, 80.40377807617188, 1.121...\n",
       "187    [-425.58892822265625, 122.54962158203125, -30....\n",
       "317    [-439.25750732421875, 150.1184539794922, -16.1...\n",
       "158    [-453.8094482421875, 120.584716796875, -17.251...\n",
       "Name: filepath, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_features is now an array of arrays\n",
    "test_features = test['filepath'].apply(extract_features)\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202    [-388.9583435058594, 90.2202377319336, -9.0481...\n",
       "151    [-636.6281127929688, 79.7216796875, -25.271593...\n",
       "293    [-399.783203125, 133.75177001953125, -23.45753...\n",
       "268    [-567.4603881835938, 119.63312530517578, 35.07...\n",
       "197    [-506.3456115722656, 95.40189361572266, 5.7141...\n",
       "Name: filepath, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_features[114])\n",
    "# just an array with 40 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into X and Y where X is the features and Y is the label (name of speaker)\n",
    "# remember that each array is still in the same order as above \n",
    "# so each element in X_train corresponds to an element in Y_train at the same index\n",
    "X_train = train_features.tolist()\n",
    "X_test = test_features.tolist()\n",
    "Y_train = train['speaker'].tolist()\n",
    "Y_test = test['speaker'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker: bfeciyuh\n",
      "Features: [-597.6613159179688, 75.76461029052734, -2.4160850048065186, 10.877646446228027, -7.995478630065918, 13.980165481567383, -13.169893264770508, 0.2100803703069687, 4.426782131195068, -5.444142818450928, 4.540070533752441, -6.761120796203613, -2.2482190132141113, 0.3148479759693146, 1.0842169523239136, -2.2032830715179443, -2.1875431537628174, -1.2984910011291504, -0.3666723370552063, 3.854919672012329, -2.4984068870544434, -2.5980982780456543, -0.0878404825925827, -3.405689001083374, -0.8611510396003723, 2.0397136211395264, -2.844575881958008, -2.659059524536133, -2.696981430053711, -2.453705072402954, -1.3845765590667725, -4.259166240692139, -2.073028326034546, -1.8004119396209717, -1.030044674873352, 1.810433268547058, 2.6391336917877197, 2.7678656578063965, 1.492274284362793, 1.3482919931411743]: \n"
     ]
    }
   ],
   "source": [
    "# now X_train is a 2d array, and each array is the long array of mfccs\n",
    "print(\"Speaker: {}\".format(Y_train[0]))\n",
    "print(\"Features: {}: \".format(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hot encode y \n",
    "lb = LabelEncoder()\n",
    "Y_train_encoded = to_categorical(lb.fit_transform(Y_train))\n",
    "Y_test_encoded = to_categorical(lb.fit_transform(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_encoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train[1])) # array of 40 elements (mean of mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train[0]))\n",
    "print(len(Y_train_encoded[0])) # number of unique speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254, 40)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(40, input_shape=(40,), activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.25))  \n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))    \n",
    "\n",
    "model.add(Dense(80, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.3557 - accuracy: 0.2193 - val_loss: 4.0187 - val_accuracy: 0.0769\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.2457 - accuracy: 0.2368 - val_loss: 4.0001 - val_accuracy: 0.0769\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.2610 - accuracy: 0.2807 - val_loss: 3.9818 - val_accuracy: 0.0769\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.1902 - accuracy: 0.2807 - val_loss: 3.9541 - val_accuracy: 0.0769\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.1932 - accuracy: 0.2193 - val_loss: 3.9357 - val_accuracy: 0.0769\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.1643 - accuracy: 0.2281 - val_loss: 3.9123 - val_accuracy: 0.0769\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 3.1239 - accuracy: 0.3202 - val_loss: 3.8947 - val_accuracy: 0.0769\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.0506 - accuracy: 0.2982 - val_loss: 3.8738 - val_accuracy: 0.0769\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.0364 - accuracy: 0.3114 - val_loss: 3.8490 - val_accuracy: 0.0769\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.9257 - accuracy: 0.3509 - val_loss: 3.8244 - val_accuracy: 0.0769\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0600 - accuracy: 0.2719 - val_loss: 3.7998 - val_accuracy: 0.0769\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.0046 - accuracy: 0.2807 - val_loss: 3.7745 - val_accuracy: 0.0769\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3.0089 - accuracy: 0.2632 - val_loss: 3.7546 - val_accuracy: 0.0769\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.9126 - accuracy: 0.2895 - val_loss: 3.7420 - val_accuracy: 0.0769\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.8214 - accuracy: 0.3509 - val_loss: 3.7014 - val_accuracy: 0.1154\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.8542 - accuracy: 0.3202 - val_loss: 3.6813 - val_accuracy: 0.1154\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.7470 - accuracy: 0.3860 - val_loss: 3.6509 - val_accuracy: 0.1154\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 2.7542 - accuracy: 0.3553 - val_loss: 3.6321 - val_accuracy: 0.1154\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.6525 - accuracy: 0.3684 - val_loss: 3.6062 - val_accuracy: 0.1923\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.7008 - accuracy: 0.3816 - val_loss: 3.5723 - val_accuracy: 0.1923\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, Y_train_encoded, batch_size=256, epochs=20, validation_split=.1)# , callbacks=[early_stop]) #, validation_data=(X_test_scaled, Y_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
