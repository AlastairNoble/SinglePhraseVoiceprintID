{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = os.listdir('alexa/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alexa/alastair/1.wav</td>\n",
       "      <td>alastair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alexa/alastair/2.wav</td>\n",
       "      <td>alastair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alexa/alastair/3.wav</td>\n",
       "      <td>alastair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alexa/alastair/5.wav</td>\n",
       "      <td>alastair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alexa/anfcucvo/1.wav</td>\n",
       "      <td>anfcucvo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               filepath   speaker\n",
       "0  alexa/alastair/1.wav  alastair\n",
       "1  alexa/alastair/2.wav  alastair\n",
       "2  alexa/alastair/3.wav  alastair\n",
       "3  alexa/alastair/5.wav  alastair\n",
       "4  alexa/anfcucvo/1.wav  anfcucvo"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['filepath', 'speaker'])\n",
    "for speaker in speakers:\n",
    "    files = os.listdir('alexa/{}/'.format(speaker))\n",
    "    for file in files:\n",
    "        filepath = 'alexa/{}/{}'.format(speaker, file)\n",
    "        df = df.append({'filepath':filepath, 'speaker':speaker}, ignore_index=True)\n",
    "print(len(speakers))\n",
    "df.head() # this is just a print statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>alexa/vgemoinn/4.wav</td>\n",
       "      <td>vgemoinn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>alexa/dnkhkmfq/1.wav</td>\n",
       "      <td>dnkhkmfq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>alexa/jvvfnxlp/2.wav</td>\n",
       "      <td>jvvfnxlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>alexa/zzgleilo/3.wav</td>\n",
       "      <td>zzgleilo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>alexa/kxiphqej/1.wav</td>\n",
       "      <td>kxiphqej</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 filepath   speaker\n",
       "294  alexa/vgemoinn/4.wav  vgemoinn\n",
       "41   alexa/dnkhkmfq/1.wav  dnkhkmfq\n",
       "128  alexa/jvvfnxlp/2.wav  jvvfnxlp\n",
       "367  alexa/zzgleilo/3.wav  zzgleilo\n",
       "173  alexa/kxiphqej/1.wav  kxiphqej"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size = 0.29, stratify = df['speaker'])\n",
    "# the stratify parameter makes the function split data evenly over the speakers column\n",
    "# this is so we dont get all files of the same speaker in the test set and not the training set\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(filename):\n",
    "    \n",
    "    X, sample_rate = librosa.load(filename, res_type='kaiser_fast')\n",
    "    \n",
    "    # librosa returns an array of 40 arrays, one for each mfcc\n",
    "    # np.mean takes the mean of each array, so we will be left with an array of size 40\n",
    "    # the n_mfcc=40 parameter means return 40 mfccs\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "    \n",
    "    # plp = librosa.beat.plp(y=X, sr=22050, onset_envelope=None, hop_length=512, win_length=99, tempo_min=30, tempo_max=300, prior=None)\n",
    "    \n",
    "    return mfccs.tolist()#  + plp.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out the function on one of the files\n",
    "# print(len(extract_features(train['filepath'][37])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the extract features to every element in train and test\n",
    "train_features = train['filepath'].apply(extract_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294    [-399.54132080078125, 129.24896240234375, -26....\n",
       "41     [-470.98406982421875, 124.64154052734375, 1.92...\n",
       "128    [-406.5012512207031, 83.7170181274414, 12.6531...\n",
       "367    [-421.73419189453125, 104.6003189086914, -18.9...\n",
       "173    [-587.8046264648438, 80.37097930908203, -14.78...\n",
       "Name: filepath, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_features is now an array of arrays\n",
    "test_features = test['filepath'].apply(extract_features)\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_features[37])\n",
    "# just an array with 40 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into X and Y where X is the features and Y is the label (name of speaker)\n",
    "# remember that each array is still in the same order as above \n",
    "# so each element in X_train corresponds to an element in Y_train at the same index\n",
    "X_train = train_features.tolist()\n",
    "X_test = test_features.tolist()\n",
    "Y_train = train['speaker'].tolist()\n",
    "Y_test = test['speaker'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker: vgemoinn\n",
      "Features: [-399.54132080078125, 129.24896240234375, -26.860309600830078, 25.929628372192383, -9.587641716003418, 8.800304412841797, -0.8646549582481384, 7.1240410804748535, -0.9060578346252441, 4.101642608642578, 13.863786697387695, -1.5559594631195068, 5.053192615509033, -3.6457841396331787, 1.2464885711669922, -1.319087266921997, 2.4215571880340576, 4.819954872131348, -0.2557099759578705, 3.449850082397461, -0.3846716284751892, 0.3831017017364502, -0.18064607679843903, 2.589801073074341, -0.454228013753891, -3.7038257122039795, 0.2175537347793579, 1.5566868782043457, -0.5052340030670166, -0.9919822812080383, 0.4876585304737091, -0.30659282207489014, 0.18528155982494354, -2.0200259685516357, -1.7635644674301147, -1.5095770359039307, -1.8632760047912598, -1.0368870496749878, -1.17448890209198, -1.1344026327133179]: \n"
     ]
    }
   ],
   "source": [
    "# now X_train is a 2d array, and each array is the long array of mfccs\n",
    "print(\"Speaker: {}\".format(Y_train[0]))\n",
    "print(\"Features: {}: \".format(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hot encode y \n",
    "lb = LabelEncoder()\n",
    "\n",
    "Y_train_encoded = to_categorical(lb.fit_transform(Y_train))\n",
    "Y_test_encoded = to_categorical(lb.fit_transform(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: ghmcwtzk\n",
      "encoded label: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"label: \" + str(Y_train[44]))\n",
    "print(\"encoded label: \" + str(Y_test_encoded[35]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_train_encoded[0])) # number of unique speakers\n",
    "print(len(Y_test_encoded[0])) # number of unique speakers\n",
    "# THESE NEED TO BE THE SAME OR THERE WILL BE AN ERROR. if they are different then increase test_size in the train_test_split line above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261, 40)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(40, input_shape=(40,), activation = 'relu'))\n",
    "model.add(Dropout(0.01))\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.01))  \n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.01))    \n",
    "\n",
    "model.add(Dense(len(Y_train_encoded[0]), activation = 'softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 4.5087 - accuracy: 0.0038 - val_loss: 4.3724 - val_accuracy: 0.0648\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.3395 - accuracy: 0.0843 - val_loss: 4.3104 - val_accuracy: 0.0833\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.2654 - accuracy: 0.0881 - val_loss: 4.2593 - val_accuracy: 0.1111\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.1970 - accuracy: 0.1226 - val_loss: 4.2079 - val_accuracy: 0.1296\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 4.1283 - accuracy: 0.1609 - val_loss: 4.1639 - val_accuracy: 0.1389\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 4.0717 - accuracy: 0.1839 - val_loss: 4.1223 - val_accuracy: 0.1296\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.0228 - accuracy: 0.1724 - val_loss: 4.0821 - val_accuracy: 0.1389\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.9760 - accuracy: 0.1762 - val_loss: 4.0381 - val_accuracy: 0.1389\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.9331 - accuracy: 0.1724 - val_loss: 4.0103 - val_accuracy: 0.1481\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.8923 - accuracy: 0.1877 - val_loss: 3.9783 - val_accuracy: 0.1574\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.8624 - accuracy: 0.1992 - val_loss: 3.9344 - val_accuracy: 0.1389\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.8062 - accuracy: 0.1609 - val_loss: 3.8908 - val_accuracy: 0.1204\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.7625 - accuracy: 0.1533 - val_loss: 3.8501 - val_accuracy: 0.1389\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.7010 - accuracy: 0.1801 - val_loss: 3.8143 - val_accuracy: 0.1111\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.6609 - accuracy: 0.1724 - val_loss: 3.7726 - val_accuracy: 0.1481\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.6139 - accuracy: 0.1839 - val_loss: 3.7275 - val_accuracy: 0.1944\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.5478 - accuracy: 0.2107 - val_loss: 3.6767 - val_accuracy: 0.2130\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.4912 - accuracy: 0.2490 - val_loss: 3.6306 - val_accuracy: 0.2407\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.4427 - accuracy: 0.2874 - val_loss: 3.5915 - val_accuracy: 0.2407\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.3850 - accuracy: 0.3142 - val_loss: 3.5541 - val_accuracy: 0.2593\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.3326 - accuracy: 0.3448 - val_loss: 3.4983 - val_accuracy: 0.2500\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.2717 - accuracy: 0.3678 - val_loss: 3.4455 - val_accuracy: 0.2685\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.2190 - accuracy: 0.3870 - val_loss: 3.4008 - val_accuracy: 0.3148\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.1622 - accuracy: 0.4215 - val_loss: 3.3497 - val_accuracy: 0.3241\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.0950 - accuracy: 0.4521 - val_loss: 3.2987 - val_accuracy: 0.3519\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.0274 - accuracy: 0.4866 - val_loss: 3.2468 - val_accuracy: 0.3148\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.9661 - accuracy: 0.4406 - val_loss: 3.2037 - val_accuracy: 0.3426\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.9158 - accuracy: 0.4521 - val_loss: 3.1569 - val_accuracy: 0.3426\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.8517 - accuracy: 0.4981 - val_loss: 3.1007 - val_accuracy: 0.3981\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.7849 - accuracy: 0.5172 - val_loss: 3.0573 - val_accuracy: 0.3981\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.7405 - accuracy: 0.5211 - val_loss: 3.0194 - val_accuracy: 0.3981\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.6784 - accuracy: 0.5172 - val_loss: 2.9651 - val_accuracy: 0.4259\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.6048 - accuracy: 0.5479 - val_loss: 2.9202 - val_accuracy: 0.4167\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.5436 - accuracy: 0.5364 - val_loss: 2.8858 - val_accuracy: 0.4259\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.5058 - accuracy: 0.5709 - val_loss: 2.8358 - val_accuracy: 0.4259\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.4325 - accuracy: 0.5977 - val_loss: 2.7931 - val_accuracy: 0.4259\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.3811 - accuracy: 0.5939 - val_loss: 2.7419 - val_accuracy: 0.4722\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.3165 - accuracy: 0.6322 - val_loss: 2.6860 - val_accuracy: 0.4167\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.2739 - accuracy: 0.6054 - val_loss: 2.6477 - val_accuracy: 0.4444\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.2032 - accuracy: 0.6207 - val_loss: 2.5917 - val_accuracy: 0.4815\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.1288 - accuracy: 0.6628 - val_loss: 2.5323 - val_accuracy: 0.4907\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.0843 - accuracy: 0.6782 - val_loss: 2.4817 - val_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.0359 - accuracy: 0.7088 - val_loss: 2.4454 - val_accuracy: 0.4722\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.9743 - accuracy: 0.6935 - val_loss: 2.3948 - val_accuracy: 0.5463\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.9169 - accuracy: 0.7356 - val_loss: 2.3405 - val_accuracy: 0.5556\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.8534 - accuracy: 0.7395 - val_loss: 2.3065 - val_accuracy: 0.5741\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.8002 - accuracy: 0.7663 - val_loss: 2.2628 - val_accuracy: 0.5463\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.7657 - accuracy: 0.7778 - val_loss: 2.2288 - val_accuracy: 0.5370\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.7024 - accuracy: 0.7893 - val_loss: 2.1828 - val_accuracy: 0.5648\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.6715 - accuracy: 0.7931 - val_loss: 2.1202 - val_accuracy: 0.5556\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.6099 - accuracy: 0.7854 - val_loss: 2.1024 - val_accuracy: 0.5648\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.5717 - accuracy: 0.7969 - val_loss: 2.0627 - val_accuracy: 0.5370\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.5249 - accuracy: 0.7969 - val_loss: 2.0169 - val_accuracy: 0.5463\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.4697 - accuracy: 0.8314 - val_loss: 1.9750 - val_accuracy: 0.5556\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.4505 - accuracy: 0.8008 - val_loss: 1.9407 - val_accuracy: 0.5648\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.3795 - accuracy: 0.8238 - val_loss: 1.9263 - val_accuracy: 0.5741\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.3585 - accuracy: 0.8238 - val_loss: 1.8859 - val_accuracy: 0.5833\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.3062 - accuracy: 0.8391 - val_loss: 1.8508 - val_accuracy: 0.6111\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 1.2623 - accuracy: 0.8391 - val_loss: 1.8297 - val_accuracy: 0.6019\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.2309 - accuracy: 0.8276 - val_loss: 1.8030 - val_accuracy: 0.5833\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.1974 - accuracy: 0.8352 - val_loss: 1.7682 - val_accuracy: 0.6019\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.1847 - accuracy: 0.8582 - val_loss: 1.6928 - val_accuracy: 0.6667\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.1227 - accuracy: 0.8736 - val_loss: 1.6846 - val_accuracy: 0.6667\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.0879 - accuracy: 0.8697 - val_loss: 1.6443 - val_accuracy: 0.6574\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.0320 - accuracy: 0.8774 - val_loss: 1.6098 - val_accuracy: 0.6759\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.0107 - accuracy: 0.9119 - val_loss: 1.5851 - val_accuracy: 0.6759\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.9732 - accuracy: 0.8736 - val_loss: 1.5781 - val_accuracy: 0.6667\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.9386 - accuracy: 0.9119 - val_loss: 1.5435 - val_accuracy: 0.6667\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.9118 - accuracy: 0.8736 - val_loss: 1.5358 - val_accuracy: 0.6667\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8862 - accuracy: 0.8889 - val_loss: 1.5047 - val_accuracy: 0.7037\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8573 - accuracy: 0.9119 - val_loss: 1.4511 - val_accuracy: 0.7130\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.8125 - accuracy: 0.9310 - val_loss: 1.4117 - val_accuracy: 0.7222\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.8005 - accuracy: 0.9272 - val_loss: 1.3957 - val_accuracy: 0.6852\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7560 - accuracy: 0.9157 - val_loss: 1.3717 - val_accuracy: 0.7222\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7261 - accuracy: 0.9349 - val_loss: 1.3888 - val_accuracy: 0.6944\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7312 - accuracy: 0.9234 - val_loss: 1.3438 - val_accuracy: 0.7130\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6983 - accuracy: 0.9310 - val_loss: 1.2946 - val_accuracy: 0.7222\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6584 - accuracy: 0.9425 - val_loss: 1.3102 - val_accuracy: 0.6759\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6641 - accuracy: 0.9310 - val_loss: 1.2964 - val_accuracy: 0.7037\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6309 - accuracy: 0.9310 - val_loss: 1.2609 - val_accuracy: 0.7130\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6152 - accuracy: 0.9272 - val_loss: 1.2813 - val_accuracy: 0.6852\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6162 - accuracy: 0.9080 - val_loss: 1.2387 - val_accuracy: 0.6852\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6018 - accuracy: 0.9080 - val_loss: 1.2067 - val_accuracy: 0.6944\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5502 - accuracy: 0.9425 - val_loss: 1.1814 - val_accuracy: 0.7130\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5267 - accuracy: 0.9502 - val_loss: 1.1923 - val_accuracy: 0.7222\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5305 - accuracy: 0.9349 - val_loss: 1.1943 - val_accuracy: 0.7222\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5068 - accuracy: 0.9425 - val_loss: 1.1609 - val_accuracy: 0.7130\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4927 - accuracy: 0.9579 - val_loss: 1.1342 - val_accuracy: 0.7315\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4778 - accuracy: 0.9425 - val_loss: 1.1216 - val_accuracy: 0.7315\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4904 - accuracy: 0.9464 - val_loss: 1.1239 - val_accuracy: 0.7222\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4727 - accuracy: 0.9540 - val_loss: 1.0818 - val_accuracy: 0.7222\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4381 - accuracy: 0.9655 - val_loss: 1.0740 - val_accuracy: 0.7315\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4073 - accuracy: 0.9540 - val_loss: 1.0609 - val_accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4059 - accuracy: 0.9617 - val_loss: 1.0274 - val_accuracy: 0.7500\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3824 - accuracy: 0.9540 - val_loss: 1.0333 - val_accuracy: 0.7222\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3616 - accuracy: 0.9693 - val_loss: 1.0549 - val_accuracy: 0.7130\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4152 - accuracy: 0.9272 - val_loss: 1.0211 - val_accuracy: 0.7407\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3610 - accuracy: 0.9579 - val_loss: 1.0233 - val_accuracy: 0.7593\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3406 - accuracy: 0.9770 - val_loss: 1.0031 - val_accuracy: 0.7593\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3154 - accuracy: 0.9693 - val_loss: 0.9774 - val_accuracy: 0.7685\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, Y_train_encoded, batch_size=256, epochs=100, validation_data=(X_test_scaled, Y_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_speaker(file):\n",
    "\n",
    "    labels = Y_train_encoded.tolist() # list of the encoded labels from training \n",
    "\n",
    "    to_predict = [alastair] # list of data for the model to predict, just one item for now\n",
    "    predictions = model.predict(to_predict) # returns a list of predictions \n",
    "    al = predictions[0].tolist() # take the first element which is the prediciton for the first element in to_predict, remember this is still one hot encoded so it is a big array of 0s and 1s\n",
    "    al_float = [int(i) for i in al] # convert it to floats\n",
    "\n",
    "    prediction_ind = labels.index(al_float) # index of predicted label\n",
    "\n",
    "    prediction = Y_train[prediction_ind]\n",
    "\n",
    "    return prediction\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "speaker: alastair\n"
     ]
    }
   ],
   "source": [
    "alastair = extract_features(\"test/alastair.wav\") # test sample of alastair saying alexa - seperate from training data\n",
    "\n",
    "print(\"speaker: \" + predict_speaker(alastair))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "say 'Alexa' in: 3\n",
      "2\n",
      "1\n",
      "* recording\n",
      "* done recording\n",
      "alastair\n"
     ]
    }
   ],
   "source": [
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 3\n",
    "WAVE_OUTPUT_FILENAME = \"test/audio_input.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "print(\"say 'Alexa' in: 3\")\n",
    "for i in range(2,0,-1):\n",
    "    time.sleep(1)\n",
    "    print (i)\n",
    "time.sleep(1)\n",
    "\n",
    "print(\"* recording\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"* done recording\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n",
    "\n",
    "print(predict_speaker(WAVE_OUTPUT_FILENAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
